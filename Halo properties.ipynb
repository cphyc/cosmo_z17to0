{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from IPython.core.magic import register_cell_magic, cell_magic\n",
    "\n",
    "@register_cell_magic\n",
    "def parallel(line, cell):\n",
    "    from os import environ\n",
    "    parallel = bool(environ.get('PARALLEL', False))\n",
    "    if parallel:\n",
    "        if '--except' in line:\n",
    "            print('Skipping cell when in parallel')\n",
    "            pass\n",
    "        else:\n",
    "            get_ipython().run_cell_magic('px', '--local', cell)\n",
    "    else:\n",
    "        if '--only' in line:\n",
    "            print('Skipping cell when not in parallel')\n",
    "            return\n",
    "        else:\n",
    "            get_ipython().run_cell(cell)\n",
    "            \n",
    "@register_cell_magic\n",
    "def comment(line, cell):\n",
    "    '''Comment a cell.'''\n",
    "    print('Skipping cell.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%parallel --only\n",
    "from IPython import parallel\n",
    "c = parallel.Client()\n",
    "view = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%parallel --except\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%parallel\n",
    "%load_ext Cython\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%parallel\n",
    "%%cython\n",
    "cimport cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "#from cython.parallel import prange\n",
    "\n",
    "ctypedef double DTYPE_t\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "\n",
    "def compute_inertia_tensor_1(np.ndarray[DTYPE_t, ndim=1] mass, np.ndarray[DTYPE_t, ndim=2] pos, no_divide_by_mass=False):\n",
    "    '''Takes the mass and positions of particles and return the inertia tensor'''\n",
    "    cdef int i, j\n",
    "    cdef np.ndarray[DTYPE_t, ndim=2] I_t, tmp_pos\n",
    "    cdef np.ndarray[DTYPE_t, ndim=1] means\n",
    "    cdef DTYPE_t tmp, mtot\n",
    "    \n",
    "    I_t = np.zeros((3, 3), dtype=np.double)\n",
    "    tmp_pos = np.zeros_like(pos)\n",
    "    mtot = np.sum(mass)\n",
    "    \n",
    "    # remove mean from positions\n",
    "    means = np.mean(pos, 0)\n",
    "    \n",
    "    for j in range(pos.shape[0]):\n",
    "        for i in range(pos.shape[1]):\n",
    "            tmp_pos[j, i] = pos[j, i] - means[i]\n",
    "    \n",
    "    for i in range(3):\n",
    "        for j in range(i, 3):\n",
    "            tmp = 0\n",
    "            for k in range(pos.shape[0]):\n",
    "                tmp = tmp + mass[k]*tmp_pos[k, i]*tmp_pos[k, j]\n",
    "            I_t[i, j] = tmp\n",
    "            I_t[j, i] = tmp\n",
    "    if no_divide_by_mass:\n",
    "        return I_t\n",
    "    else:\n",
    "        return I_t/mtot\n",
    "\n",
    "def compute_inertia_tensor(mass, pos, no_divide_by_mass=False):\n",
    "    tmp = pos - np.mean(pos, 0)\n",
    "    if no_divide_by_mass:\n",
    "        return np.dot(mass*tmp.T, tmp)\n",
    "    else:\n",
    "        return np.dot(mass*tmp.T, tmp) / np.sum(mass)\n",
    "\n",
    "def project_points(x, y, z, a, b, c):\n",
    "    \"\"\"\n",
    "    Projects the points with coordinates x, y, z onto the plane\n",
    "    defined by a*x + b*y + c*z = 1\n",
    "    \n",
    "    From http://stackoverflow.com/questions/17836880/orthogonal-projection-with-numpy\n",
    "    \"\"\"\n",
    "    vector_norm = a*a + b*b + c*c\n",
    "    normal_vector = np.array([a, b, c]) / np.sqrt(vector_norm)\n",
    "    point_in_plane = np.array([a, b, c]) / vector_norm\n",
    "\n",
    "    points = np.column_stack((x, y, z))\n",
    "    points_from_point_in_plane = points - point_in_plane\n",
    "    proj_onto_normal_vector = np.dot(points_from_point_in_plane,\n",
    "                                     normal_vector)\n",
    "    proj_onto_plane = (points_from_point_in_plane -\n",
    "                       proj_onto_normal_vector[:, None]*normal_vector)\n",
    "\n",
    "    return point_in_plane + proj_onto_plane\n",
    "\n",
    "cdef DTYPE_t correct(DTYPE_t el):\n",
    "    '''Realign the particles when they're too far appart'''\n",
    "    if el < 0.5:\n",
    "        return el\n",
    "    else:\n",
    "        return el - 1.0\n",
    "v_correct = np.vectorize(correct)\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def correct_particles(np.ndarray[DTYPE_t, ndim=2] particles):\n",
    "    cdef int i, j\n",
    "    cdef np.ndarray[DTYPE_t, ndim=1] maxis, minis\n",
    "    cdef np.ndarray[DTYPE_t, ndim=2] ret\n",
    "    maxis = np.max(particles, 0)\n",
    "    minis = np.min(particles, 0)\n",
    "    \n",
    "    ret = particles\n",
    "    for i in range(3):\n",
    "        if maxis[i] - minis[i] > 0.5:\n",
    "            print('Reshaping %s' % i)\n",
    "            for j in range(particles.shape[0]):\n",
    "                if (ret[j, i] > 0.5):\n",
    "                    ret[j, i] = ret[j, i] - 1.0\n",
    "    return ret\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "cdef int binary_search(np.ndarray[int, ndim=1] a, int x, int left, int right):\n",
    "    cdef int lo, hi, mid, midval\n",
    "    lo = left\n",
    "    hi = right\n",
    "    while lo < hi:\n",
    "        mid = (lo+hi)/2\n",
    "        midval = a[mid]\n",
    "        if midval < x:\n",
    "            lo = mid+1\n",
    "        elif midval > x: \n",
    "            hi = mid\n",
    "        else:\n",
    "            return mid\n",
    "    return -1\n",
    "        \n",
    "def quicksearch_2(np.ndarray array, np.ndarray elements):\n",
    "    '''Searches elements in array, where array and elements\n",
    "    are both sorted'''\n",
    "    cdef int left, right, pos\n",
    "    positions = np.zeros(len(elements), dtype=int)\n",
    "    left = 0\n",
    "    right = len(array)\n",
    "    for i in range(len(elements)):\n",
    "        pos = binary_search(array, elements[i], left, right)\n",
    "        if pos >-1:\n",
    "            left = pos\n",
    "        positions[i] = pos\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def quicksearch(np.ndarray[int, ndim=1] array, np.ndarray[int, ndim=1] elements):\n",
    "    '''Returns the index of the elements in the array, asserting elements and array are ordered.'''\n",
    "    cdef int i, ubound\n",
    "    cdef np.ndarray[long, ndim=1] res, res1\n",
    "    \n",
    "    res = np.searchsorted(array, elements)\n",
    "    \n",
    "    ubound = len(array)\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        if res[i] == 0 and elements[i] != array[res[i]]:\n",
    "            res[i] = -1\n",
    "        elif res[i] == ubound:\n",
    "            res[i] = -1\n",
    "    return res\n",
    "\n",
    "def search_mask(np.ndarray[int, ndim=1] array, np.ndarray[int, ndim=1] elements):\n",
    "    '''Returns the index of the elements in the array, asserting elements and array are ordered.'''\n",
    "    return np.where(quicksearch(array, elements) >= 0, True, False)\n",
    "\n",
    "def quicksearch_1(np.ndarray[int, ndim=1] array, np.ndarray[int, ndim=1] elements):\n",
    "    cdef int i, ubound\n",
    "    cdef np.ndarray[long, ndim=1] res0, res1\n",
    "    res0 = np.searchsorted(array, elements, side='left')\n",
    "    res1 = np.searchsorted(array, elements, side='right')\n",
    "    return np.where(res1-res0 == 1, res0, -1)\n",
    "\n",
    "def in_region(np.ndarray center, DTYPE_t radius):\n",
    "    cdef DTYPE_t r2\n",
    "    r2 = radius**2\n",
    "    def tmp(np.ndarray[DTYPE_t, ndim=2] pts):\n",
    "        cdef np.ndarray pos2\n",
    "        pos2 = np.sum(np.power(pts, 2) - center, 1)\n",
    "        return pos2 < r2\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 1, 1],\n",
    "              [1, 2, 3]], dtype=np.float)\n",
    "m = np.array([0.1, 0.1, 0.1])\n",
    "x = np.random.rand(100, 3)\n",
    "m = np.random.rand(100)\n",
    "%timeit compute_inertia_tensor(m, x)\n",
    "%timeit compute_inertia_tensor_1(m, x)\n",
    "compute_inertia_tensor(m, x), compute_inertia_tensor_1(m, x), compute_inertia_tensor(m, x)-compute_inertia_tensor_1(m, x)<1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%parallel\n",
    "%autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tools as t\n",
    "import pymses\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.linalg as linalg\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "#from cython_module import *\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%comment\n",
    "%%px --local\n",
    "def compute_inertia_tensor(mass,\n",
    "                           pos):\n",
    "    '''Takes the mass and positions of particles and return the inertia tensor'''\n",
    "    #cdef int i, j\n",
    "    #cdef np.ndarray[DTYPE_t, ndim=2] tmp, I_t\n",
    "    I_t = np.zeros((3, 3))\n",
    "    for i in range(3):\n",
    "        for j in range(i, 3):\n",
    "            tmp = np.sum(mass*pos[:, i]*pos[:, j]) / np.sum(mass)\n",
    "            I_t[i, j] = tmp\n",
    "            I_t[j, i] = tmp\n",
    "    return I_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get inertia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "halo_inertia = pd.read_csv('lists/halo.00002.inertia_tensor.dat', delim_whitespace=True).set_index('halo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "halo_inertia.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of halos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "halo_list = pd.read_csv('lists/list_halo.dat',\n",
    "                        delim_whitespace=True,\n",
    "                        skiprows=1,\n",
    "                        names=['id', 'level', 'mass', 'x', 'y', 'z', 'r']).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "halo_list[halo_list.mass > 1e12].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "\n",
    "unit, ncol, nrow = t.io.read_list_header('lists/list_kingal_00782.dat')\n",
    "gal_dynamics = pd.DataFrame(t.io.read_list_data_reals(unit, ncol, nrow),\n",
    "                            columns=['id', 'vtheta', 'dvx', 'dvy', 'dvz', 'mass', 'x', 'y', 'z']).set_index('id')\n",
    "\n",
    "gd = gal_dynamics\n",
    "gal_dynamics['sigma_over_vtheta'] = 1./3*np.sqrt((gd.dvx**2 + gd.dvy**2 + gd.dvz**2)) / np.abs(gd.vtheta)\n",
    "del gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gal_dynamics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy to halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "association = pd.read_csv('lists/associated_halogal_782.dat', delim_whitespace=True, skiprows=1,\n",
    "                          names=['halo_id', 'level', 'halo_mass', 'gal_id', 'gal_mass']).set_index('halo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "association.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Halo to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "filename = 'lists/halo_to_cpu.00002.m<1e12.dat'\n",
    "with open(filename, 'r') as f:\n",
    "    rows, cols = [int(e) for e in f.readline().replace('\\n', '').split()]\n",
    "    names = ['halo_id'] + ['cpu_%i' % cpu for cpu in range(1, cols+1)] \n",
    "\n",
    "halo_to_cpu = pd.read_csv(filename, delim_whitespace=True, engine='c', skiprows=1,\n",
    "                          names=names).set_index('halo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "halo_to_cpu[halo_to_cpu.cpu_1 > 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get brick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "halos = t.io.read_brick('/data52/Horizon-AGN/TREE_DM_celldx2kpc_SC0.9r/tree_bricks782', low_mem=True, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with 1 halo of mass ~1e12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halo_list[halo_list.mass > 1e12].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id = 17316\n",
    "cpus = [cpu for cpu in list(halo_to_cpu.loc[id]) if cpu > 0]\n",
    "halo_to_cpu.loc[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_parts = pd.DataFrame()\n",
    "for cpu in cpus:\n",
    "    print('Reading cpu', cpu)\n",
    "    filename = '/data52/Horizon-AGN/OUTPUT_DIR/output_00002/part_00002.out{:0>5}'.format(cpu)\n",
    "    _,_,_, _tmp = t.io.read_particles(filename)\n",
    "    _tmp['cpu'] = cpu\n",
    "    raw_parts = raw_parts.append(_tmp)\n",
    "raw_parts = raw_parts.set_index('ids')\n",
    "raw_parts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_mask = np.unique([i for i in quicksearch(np.array(raw_parts.index, dtype=np.int32), halos[id-1]['members']) if i >= 0])\n",
    "data_mask\n",
    "#[filter(s) for _, s in tqdm(raw_parts.iterrows())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xyz = correct_particles(np.copy(np.array(raw_parts[['x', 'y', 'z']])))\n",
    "raw_parts.x = xyz[:, 0]\n",
    "raw_parts.y = xyz[:, 1]\n",
    "raw_parts.z = xyz[:, 2]\n",
    "raw_parts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_parts_2 = raw_parts.iloc[data_mask]\n",
    "print('Found', raw_parts_2.x.size, 'particles, expected', len(halos[id-1]['members']))\n",
    "raw_parts_2.head()\n",
    "means = np.array(raw_parts_2[['x', 'y', 'z']].mean())\n",
    "sigmas = np.array(raw_parts_2[['x', 'y', 'z']].std())\n",
    "del raw_parts\n",
    "raw_parts_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ro = pymses.RamsesOutput('/data52/Horizon-AGN/OUTPUT_DIR/', 2)\n",
    "ro.verbose = True\n",
    "parts = ro.particle_source([\"pos\", \"mass\", \"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the cpus containing the halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Cpus in box', means-2*sigmas, means+2*sigmas)\n",
    "cpus = np.unique([c \n",
    "        for c in t.misc.get_cpu_list(means - 2*sigmas, means + 2*sigmas, ro.info['levelmax'], ro.info['dom_decomp_Hilbert_keys'])\n",
    "        if c > 0])\n",
    "print('%f cpus', len(cpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smax = np.max(sigmas)\n",
    "f = 5\n",
    "sps = []\n",
    "for i in range(3):\n",
    "    if (means[i] - f*smax < 0):\n",
    "        print(means[i] - f*smax )\n",
    "        tmp_means = np.copy(means)\n",
    "        tmp_means[i] += 1\n",
    "        sps.append(pymses.utils.regions.Sphere(tmp_means, f*smax))\n",
    "    if (means[i] + f*smax > 1.):\n",
    "        print(means[i] + f*smax )\n",
    "        tmp_means = np.copy(means)\n",
    "        tmp_means[i] -= 1\n",
    "        sps.append(pymses.utils.regions.Sphere(tmp_means, f*smax))\n",
    "sps.append(pymses.utils.regions.Sphere(means, f*smax))\n",
    "\n",
    "idFilter = pymses.filters.PointIdFilter(list(halos[id-1]['members']), parts)\n",
    "regs = [pymses.filters.RegionFilter(sp, idFilter) for sp in sps]\n",
    "#regs_id = [pymses.filters.PointIdFilter(list(halos[id-1]['members']), r) for r in regs]\n",
    "raw_parts = pd.DataFrame()\n",
    "for reg in tqdm(regs):\n",
    "    for dset in reg.iter_dsets():\n",
    "        xyz = dset.points\n",
    "        masses = dset['mass']\n",
    "        tmp = pd.DataFrame({'ids': dset['id'], 'm': dset['mass'], 'x': xyz[:, 0], 'y': xyz[:, 1], 'z': xyz[:, 2]})\n",
    "        raw_parts = raw_parts.append(tmp)\n",
    "        del tmp\n",
    "parts = raw_parts.set_index('ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(halos[id-1]['members']), parts['m'].size)\n",
    "raw_parts.describe()\n",
    "xyz = correct_particles(np.array(parts[['x', 'y', 'z']]))\n",
    "parts.x = xyz[:, 0]\n",
    "parts.y = xyz[:, 1]\n",
    "parts.z = xyz[:, 2]\n",
    "np.mean(xyz, 0), np.min(xyz, 0), np.max(xyz, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.mean(xyz, 0))\n",
    "res.loc[id:id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "I_t = compute_inertia_tensor(parts.m.as_matrix(), parts.as_matrix(['x', 'y', 'z']))\n",
    "eigvals, eigvects = np.linalg.eigh(I_t)\n",
    "each = 10\n",
    "ax.scatter3D(raw_parts.x[::each], raw_parts.y[::each], raw_parts.z[::each])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "mx, my, mz = raw_parts[['x', 'y', 'z']].mean()\n",
    "for i in range(3):\n",
    "    ax.plot([mx, mx+np.sqrt(eigvals[i])*eigvects[i, 0]],\n",
    "            [my, my+np.sqrt(eigvals[i])*eigvects[i, 1]],\n",
    "            [mz, mz+np.sqrt(eigvals[i])*eigvects[i, 2]], c='black')\n",
    "print(eigvals)\n",
    "print(eigvects)\n",
    "eigvects[0, 0], eigvects[1, 0], res.loc[id:id][['meanx', 'meany', 'meanz']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project on eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def project(x, y, z):\n",
    "    print(x, y, z)\n",
    "    return np.dot(eigvects, np.array((x, y, z)))\n",
    "vproject = np.vectorize(project)\n",
    "#vproject(parts[['x', 'y', 'z']][:100], 3)\n",
    "e0, e1, e2 = np.dot(eigvects.T, parts[['x', 'y', 'z']].T)\n",
    "parts['e0'], parts['e1'], parts['e2'] = e0, e1, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5), squeeze=True)\n",
    "proj = {}\n",
    "each = 1\n",
    "for i, xy, l in zip([0, 1, 2], ['e0 e1', 'e1 e2', 'e0 e2'], np.sqrt([eigvals[2], eigvals[1], eigvals[0]])):\n",
    "    ax = axes[i]\n",
    "    xname, yname = xy.split(' ')\n",
    "    ax.scatter(parts[xname][::each], parts[yname][::each], alpha=0.5)\n",
    "    m0, m1 = parts[[xname, yname]].mean()\n",
    "    l0, l1 = np.sqrt(eigvals[[int(xname.replace('e', '')), int(yname.replace('e', ''))]])\n",
    "    ax.plot([m0, m0+l0], [m1, m1])\n",
    "    ax.plot([m0, m0], [m1, m1+l1])\n",
    "    ax.axis('equal')\n",
    "    ax.grid('on')\n",
    "    ax.set_xlabel(xname)\n",
    "    ax.set_ylabel(yname)\n",
    "    ax.set_title(r'$\\sqrt{\\lambda} ='+'{}$'.format(l))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate density using KDE\n",
    "Take a look at https://jakevdp.github.io/blog/2013/12/01/kernel-density-estimation/ for details"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(xmin, ymin, zmin), (xmax, ymax, zmax) = (\n",
    "    parts[['x','y','z']].min(), parts[['x','y','z']].max())\n",
    "\n",
    "X, Y = np.mgrid[xmin:xmax:50j, ymin:ymax:50j] #zmin:zmax:50j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "values = np.vstack([parts.x, parts.y])\n",
    "#kernel = gaussian_kde(values)\n",
    "#fit = np.rot90(np.reshape(kernel(positions).T, X.shape))\n",
    "\n",
    "# Using scikit-learn\n",
    "kde = KernelDensity(bandwidth=0.2)\n",
    "kde.fit(positions)\n",
    "log_pdf = kde.score_samples(values)\n",
    "fit = np.exp(log_pdf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "positions.shape, values.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.imshow(fit, extent=[xmin, xmax, ymin, ymax])\n",
    "plt.scatter(parts.x, parts.y, marker='.', alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Compute the Inertia tensor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I_t = np.zeros((3, 3))\n",
    "pos = parts[['x', 'y', 'z']]\n",
    "for i in range(3):\n",
    "    for j in range(i, 3):\n",
    "        tmp = np.sum(parts.mass*pos.iloc[:, i]*pos.iloc[:, j]) / parts.mass.sum()\n",
    "        I_t[i, j] = tmp\n",
    "        I_t[j, i] = tmp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(l1, l2, l3), (e1, e2, e3) = linalg.eig(I_t)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.scatter(np.array(parts.x), np.array(parts.y))\n",
    "#plt.plot([parts.x.mean(), parts.y.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "with open('.tmp/dump', 'w') as f:\n",
    "    f.dump([halo_to_cpu, halos, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverting  halo→cpu to cpu→halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_to_halo = {}\n",
    "for i in range(1, 4096+1):\n",
    "    cpu_to_halo[i] = set()\n",
    "for halo_i, cpus in tqdm(halo_to_cpu.iterrows()):\n",
    "    for _, cpu in cpus.iteritems():\n",
    "        if (cpu > 0):\n",
    "            cpu_to_halo[cpu].add(halo_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Computing inertia tensor for all halos (this may take a long time…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "ro = pymses.RamsesOutput('/data52/Horizon-AGN/OUTPUT_DIR/', 2)\n",
    "ro.verbose = False\n",
    "ro_parts = ro.particle_source([\"pos\", \"mass\", \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%px --local\n",
    "step = 2\n",
    "# Compute our meshgrid\n",
    "txgrid = np.linspace(0, 1, step+1)\n",
    "tygrid = np.linspace(0, 1, step+1)\n",
    "tzgrid = np.linspace(0, 1, step+1)\n",
    "\n",
    "xgrid = (txgrid[1:]+txgrid[:-1])/2\n",
    "ygrid = (tygrid[1:]+tygrid[:-1])/2\n",
    "zgrid = (tzgrid[1:]+tzgrid[:-1])/2\n",
    "\n",
    "X, Y, Z = np.meshgrid(xgrid, ygrid, zgrid)\n",
    "\n",
    "# Create a list of permutations \n",
    "comb_list = list(itertools.product(range(step), range(step), range(step)))\n",
    "\n",
    "def get_halo_in_cpus(cpus):\n",
    "    '''Return the halos that are contained in the cpus.'''\n",
    "    halo_set = set()\n",
    "    for cpu in cpus:\n",
    "        halo_set.update(cpu_to_halo[cpu])\n",
    "    return halo_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "halo_read = set()\n",
    "def compute((i, j, k)):\n",
    "    halo_inertia = pd.DataFrame(columns=['id', 'xx', 'xy', 'xz', 'yy', 'yz', 'zz',\n",
    "                                         'complete', 'meanx', 'meany', 'meanz', 'nparts']).set_index('id')\n",
    "\n",
    "    center = np.array([X[i,j,k], Y[i,j,k], Z[i,j,k]])\n",
    "\n",
    "    region = pymses.filters.RegionFilter(pymses.utils.regions.Cube(center, 1.1/step), ro_parts)\n",
    "    dset   = region.flatten()\n",
    "    \n",
    "    print('Computing for region', region.region.get_bounding_box())\n",
    "\n",
    "    #for halo_i, halo in tqdm(_tmp_h_list.iterrows()):\n",
    "    for halo_i in tqdm(get_halo_in_cpus(region._data_list), nested=True):\n",
    "        try:\n",
    "            members = halos[halo_i-1]['members']\n",
    "        except:\n",
    "            print('Exception')\n",
    "            continue\n",
    "                        \n",
    "        if halo_i in halo_read:\n",
    "            #print('Skipping already fully read halo %s' % halo_i)\n",
    "            continue\n",
    "        \n",
    "        #         region_plus_id = pymses.filters.PointIdFilter(list(halos[id-1]['members']), dset_0)\n",
    "        #         dset = region_plus_id.flatten()\n",
    "\n",
    "        ids = np.unique([i for i in quicksearch(dset['id'], members) if i >=0])\n",
    "        if len(ids) == 0:\n",
    "            print('Empty !')\n",
    "            continue\n",
    "        pts = dset.points[ids]\n",
    "        xyz = np.array(correct_particles(pts), dtype=np.float)\n",
    "        masses = np.array(dset['mass'][ids], dtype=np.float)\n",
    "        #         xyz = correct_particles(dset.points)\n",
    "        #         masses = dset['mass']\n",
    "        means = np.mean(xyz, 0)\n",
    "        #print(np.mean(xyz, 0))\n",
    "        \n",
    "        halo_inertia.at[halo_i, 'meanx'] = means[0]\n",
    "        halo_inertia.at[halo_i, 'meany'] = means[1]\n",
    "        halo_inertia.at[halo_i, 'meanz'] = means[2]\n",
    "        halo_inertia.at[halo_i, 'stdx'] = np.std(xyz[:, 0])\n",
    "        halo_inertia.at[halo_i, 'stdy'] = np.std(xyz[:, 1])\n",
    "        halo_inertia.at[halo_i, 'stdz'] = np.std(xyz[:, 2])\n",
    "        halo_inertia.at[halo_i, 'nparts'] = len(masses)\n",
    "        \n",
    "        if len(masses) == len(halos[halo_i-1]['members']):\n",
    "            halo_inertia.at[halo_i, 'complete'] = True\n",
    "            halo_read.add(halo_i)\n",
    "        else:\n",
    "            halo_inertia.at[halo_i, 'complete'] = False\n",
    "            #print('Halo {} is incomplete, missing {:.2}%'.format(\n",
    "            #        halo_i, (100.*(len(halos[halo_i-1]['members']) - len(masses)) / (len(masses)))))\n",
    "\n",
    "\n",
    "        I_t = compute_inertia_tensor(masses, xyz)\n",
    "        l = ['x', 'y', 'z']\n",
    "        for i in range(3):\n",
    "            for j in range(i, 3):\n",
    "                halo_inertia.at[halo_i, l[i]+l[j]] = np.float(I_t[i,j])\n",
    "\n",
    "    return halo_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_results_p = []\n",
    "for ijk in tqdm(comb_list):\n",
    "    p_results_p.append(compute(ijk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "p_results_p = view.map_sync(compute, comb_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(p_results_p))\n",
    "res = pd.DataFrame()\n",
    "for p in p_results_p:\n",
    "    res = res.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%comment\n",
    "import pickle as pickle\n",
    "with open('halo_inertia_m_mean.dump', 'w') as f:\n",
    "    pickle.dump(p_results_p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%comment\n",
    "import pickle as pickle\n",
    "with open('halo_inertia_m_mean.dump', 'r') as f:\n",
    "    p_results_p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%comment\n",
    "import pickle as pickle\n",
    "\n",
    "with open('inertia_m_mean.pickle', 'w') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%comment\n",
    "import pickle as pickle\n",
    "\n",
    "with open('inertia_m_mean.pickle', 'r') as f:\n",
    "    res = pickle.load(f).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.describe(), halo_list[halo_list.mass > 1e12].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the eigenvalues + vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for halo_i, l in tqdm(res.iterrows()):\n",
    "    I_t = np.array([[l.xx, l.xy, l.xz],\n",
    "                    [l.xy, l.yy, l.yz],\n",
    "                    [l.xz, l.yz, l.zz]])\n",
    "    lambdas = np.linalg.eigvalsh(I_t)\n",
    "    res.at[halo_i, 'lambda0'] = lambdas[0]\n",
    "    res.at[halo_i, 'lambda1'] = lambdas[1]\n",
    "    res.at[halo_i, 'lambda2'] = lambdas[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add $\\sigma/v_\\theta$ to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = gal_dynamics.loc[association.loc[res.index]['gal_id']]\n",
    "res['sigma_over_vtheta'] = np.array(tmp['sigma_over_vtheta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot all that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(res.lambda0, res.lambda1, res.lambda2)\n",
    "ax.set_xlabel('$\\lambda_0$')\n",
    "ax.set_ylabel('$\\lambda_1$')\n",
    "ax.set_ylabel('$\\lambda_2$')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(\n",
    "    res.lambda0,\n",
    "    res.lambda1,\n",
    "    res.lambda2, label=r'$\\sigma/v_\\theta > 1$', alpha=0.5, c=res.sigma_over_vtheta)\n",
    "\n",
    "\n",
    "ax.set_xlabel('$\\lambda_0$')\n",
    "ax.set_ylabel('$\\lambda_1$')\n",
    "ax.set_ylabel('$\\lambda_2$')\n",
    "ax.grid()\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "tmp = res[res.sigma_over_vtheta > 1]\n",
    "trace = [None, None]\n",
    "trace[0] = ax.scatter(\n",
    "    np.log(tmp.lambda1),\n",
    "    np.log(tmp.lambda2), label=r'$\\sigma/v_\\theta > 1$', alpha=0.5, c='red')\n",
    "tmp = res[res.sigma_over_vtheta <= 1]\n",
    "trace[1] = ax.scatter(\n",
    "     np.log(tmp.lambda1),\n",
    "     np.log(tmp.lambda2), label=r'$\\sigma/v_\\theta \\leq 1$', alpha=0.5, c='blue')\n",
    "\n",
    "\n",
    "ax.set_xlabel('$\\lambda_1$')\n",
    "ax.set_ylabel('$\\lambda_2$')\n",
    "ax.grid()\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\lambda_2$ - $\\lambda_1$ - $\\sigma/v_\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax11 = fig.add_subplot(121)\n",
    "ax12 = fig.add_subplot(122, sharex=ax11, sharey=ax11)\n",
    "\n",
    "tmp = res[res.sigma_over_vtheta > 1]\n",
    "trace = [None, None]\n",
    "trace[0] = ax11.scatter(\n",
    "    tmp.lambda1,\n",
    "    tmp.lambda2, label=r'$\\sigma/v_\\theta > 1$', alpha=0.5, c=tmp.lambda0)\n",
    "\n",
    "tmp = res[res.sigma_over_vtheta <= 1]\n",
    "trace[1] = ax12.scatter(\n",
    "     tmp.lambda1,\n",
    "     tmp.lambda2, label=r'$\\sigma/v_\\theta \\leq 1$', alpha=0.5, c=tmp.lambda0)\n",
    "\n",
    "\n",
    "#ax.set_xlabel('$\\lambda_1$')\n",
    "#ax.set_ylabel('$\\lambda_2$')\n",
    "ax11.grid()\n",
    "ax12.grid()\n",
    "ax11.legend()\n",
    "ax12.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\lambda_2$ - $\\lambda_1$ - $\\sigma/v_\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(\n",
    "    np.log(res.lambda1),\n",
    "    np.log(res.lambda2), \n",
    "    alpha=0.5, c=np.log(res.sigma_over_vtheta))\n",
    "\n",
    "\n",
    "ax.set_xlabel('$\\lambda_0$')\n",
    "ax.set_ylabel('$\\lambda_1$')\n",
    "#ax.set_ylabel('$\\lambda_2$')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "#plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélations\n",
    "Recherche de corrélations entre $\\lambda_i$ et $\\sigma/_\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[['lambda0', 'lambda1', 'lambda2', 'sigma_over_vtheta']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%timeit res['lambda_square'] = res.eval('sqrt(lambda0**2 + lambda1**2 + lambda2**2)')\n",
    "res['lambda_square'] = np.sqrt(res.lambda0**2 + res.lambda1**2 + res.lambda2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[['lambda_square', 'sigma_over_vtheta']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucune corrélation semblerait-il…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDE des $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "res['lambda0'].plot.kde(label='$\\lambda_0$')\n",
    "res['lambda1'].plot.kde(label='$\\lambda_1$')\n",
    "res['lambda2'].plot.kde(label='$\\lambda_2$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "plt.figure(figsize=(23, 23*9/16.))\n",
    "ax = plt.gca()\n",
    "scatter_matrix(res,\n",
    "               alpha=0.5, diagonal='kde', ax=ax)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "plt.figure(figsize=(23, 23*9/16.))\n",
    "logres = np.log10(np.sqrt(res.astype(np.float)))\n",
    "ax = plt.gca()\n",
    "scatter_matrix(logres[['lambda0', 'lambda1', 'lambda2', 'sigma_over_vtheta', 'lambda_square']],\n",
    "               alpha=1, diagonal='kde', ax=ax)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapport d'asymétrie\n",
    "On travaille avec $$\\tau = \\frac{\\lambda_2}{\\lambda_1} \\propto? \\frac{\\sigma}{v_\\theta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halo_list.loc[63792]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res['tau'] = res.lambda2/res.lambda1\n",
    "res['tau'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[['tau', 'sigma_over_vtheta']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "plt.figure(figsize=(23, 23*9/16.))\n",
    "logres = np.log(res.astype(np.float))\n",
    "ax = plt.gca()\n",
    "scatter_matrix(logres[['lambda0', 'lambda1', 'lambda2', 'sigma_over_vtheta', 'lambda_square', 'tau']],\n",
    "               alpha=0.5, diagonal='kde', ax=ax)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "np.log10(res.lambda0).plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[res.lambda0 < 1e-15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
